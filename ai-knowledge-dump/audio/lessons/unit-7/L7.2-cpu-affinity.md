# L7.2: CPU Affinity & Cache Effects - Pinning Audio Threads

**Unit 7: Real-Time Audio Constraints**  
**Estimated Time:** 60-75 minutes  
**Competence Target:** Level 5 (Synthesis - can optimize CPU locality)

---

## Learning Objectives

By the end of this lesson, you will:

1. **Understand** CPU cache hierarchy (L1/L2/L3)
2. **Explain** why thread migration causes cache misses
3. **Use** `taskset` to pin process to specific core
4. **Measure** latency reduction from affinity
5. **Configure** affinity from C code (`sched_setaffinity`)
6. **Analyze** multi-core vs single-core audio strategies

---

## The Mystery: Why Does Audio Callback Time Vary?

### Unexpected Timing Variance

**Your timing measurements (from L7.1):**
```
Frame 1: Audio callback = 150 Î¼s
Frame 2: Audio callback = 180 Î¼s
Frame 3: Audio callback = 2500 Î¼s  â† Why?!
Frame 4: Audio callback = 160 Î¼s
```

**Hypothesis:** Thread moved to different CPU core!

---

## Concept 1: CPU Cache Hierarchy

### The Memory Pyramid

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ CPU Core 0    CPU Core 1    CPU Core 2 â”‚
â”‚ â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€  â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€  â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ â”‚
â”‚ L1: 32 KB     L1: 32 KB     L1: 32 KB   â”‚  â† Fastest (1 cycle)
â”‚ L2: 256 KB    L2: 256 KB    L2: 256 KB  â”‚  â† Fast (10 cycles)
â”‚ â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”‚
â”‚        L3: 8 MB (shared)                â”‚  â† Slower (40 cycles)
â”‚ â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”‚
â”‚             RAM: 16 GB                  â”‚  â† Slow (200 cycles)
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

**Key insight:** L1/L2 caches are **per-core**, not shared!

---

### What Happens When Thread Migrates

**Scenario 1: Thread stays on Core 0**
```c
Frame 1 (Core 0):
  Load samples from RAM â†’ L1 cache (200 cycles)
  Process samples (in L1) â†’ Fast!

Frame 2 (Core 0):
  Samples still in L1 cache â†’ Ultra fast! (1 cycle)
```

**Scenario 2: Thread migrates to Core 1**
```c
Frame 1 (Core 0):
  Load samples from RAM â†’ Core 0 L1 cache (200 cycles)

Frame 2 (Core 1):  â† Migrated!
  Samples not in Core 1 L1 â†’ Load from RAM again (200 cycles)
  â† "Cold cache" = slow!
```

**Result:** 2500 Î¼s instead of 150 Î¼s!

---

### Web Dev Analogy

**Without affinity:**
```javascript
// Server 1 handles request, caches user data
fetch('/api/user/123')  // 200ms (database lookup)

// Next request goes to Server 2 (load balancer)
fetch('/api/user/123')  // 200ms again! (cache miss)
```

**With affinity (sticky sessions):**
```javascript
// All requests for user 123 go to Server 1
fetch('/api/user/123')  // 200ms (database lookup)
fetch('/api/user/123')  // 5ms (from cache)
```

---

## Exercise 1: See Thread Migration

### Step 1: Monitor Which Core Your Process Uses

```bash
# Install htop if not available
sudo apt install htop

# Run your game
./game &

# In another terminal:
htop

# Press F5 (tree view), F4 (filter), type "game"
# Look at "CPU" column â€” does it jump between cores?
```

**Observation:** You'll see numbers like:
```
PID   CPU  MEM  COMMAND
1234   0   2.1  ./game   â† Core 0
1234   2   2.1  ./game   â† Migrated to Core 2!
1234   1   2.1  ./game   â† Now Core 1
```

**Problem:** Thread bounces between cores!

---

### Step 2: Pin to Single Core with `taskset`

```bash
# Run game pinned to Core 0
taskset -c 0 ./game

# Verify:
taskset -p $(pgrep game)
# Output: pid 1234's current affinity mask: 1
# Binary: 0001 = Core 0 only
```

**In htop:** CPU column stays at 0 â€” no more migration!

---

## Exercise 2: Measure Cache Impact

**Add to your code:**
```c
#include <sched.h>

void MeasureCacheMiss() {
  // Large array (1 MB) to trash cache
  static int dummy_array[256 * 1024];
  
  struct timespec start, end;
  
  // Warm up cache
  for (int i = 0; i < 100; i++) {
    dummy_array[i * 256] = i;  // Stride to avoid prefetcher
  }
  
  // Measure cold access
  clock_gettime(CLOCK_MONOTONIC, &start);
  volatile int sum = 0;
  for (int i = 0; i < 1000; i++) {
    sum += dummy_array[i * 256];
  }
  clock_gettime(CLOCK_MONOTONIC, &end);
  
  int64_t cold_ns = (end.tv_sec - start.tv_sec) * 1000000000LL +
                    (end.tv_nsec - start.tv_nsec);
  
  // Measure hot access (data in cache)
  clock_gettime(CLOCK_MONOTONIC, &start);
  sum = 0;
  for (int i = 0; i < 1000; i++) {
    sum += dummy_array[i * 256];
  }
  clock_gettime(CLOCK_MONOTONIC, &end);
  
  int64_t hot_ns = (end.tv_sec - start.tv_sec) * 1000000000LL +
                   (end.tv_nsec - start.tv_nsec);
  
  printf("Cache miss penalty: cold=%lld ns, hot=%lld ns, ratio=%.1fx\n",
         cold_ns, hot_ns, (double)cold_ns / hot_ns);
}
```

**Results:**
```
Without affinity: cold=5000 ns, hot=800 ns, ratio=6.2x
With affinity:    cold=5000 ns, hot=300 ns, ratio=16.7x
```

**Interpretation:** Hot cache is 16x faster! Affinity keeps data hot.

---

## Concept 2: Setting Affinity from Code

### Manual CPU Pinning

```c
#include <sched.h>

int LinuxSetCPUAffinity(int core_id) {
  cpu_set_t cpuset;
  CPU_ZERO(&cpuset);
  CPU_SET(core_id, &cpuset);
  
  int result = sched_setaffinity(0, sizeof(cpuset), &cpuset);
  
  if (result == -1) {
    perror("sched_setaffinity");
    return -1;
  }
  
  printf("âœ… Pinned to CPU core %d\n", core_id);
  return 0;
}

int main() {
  // Pin to core 0
  LinuxSetCPUAffinity(0);
  
  // Optionally combine with real-time priority
  LinuxSetThreadRealtime(10);  // From L7.1
  
  LinuxMainLoop();
}
```

---

### Multiple Cores Allowed

**Allow cores 0 and 1 (but not 2-3):**
```c
cpu_set_t cpuset;
CPU_ZERO(&cpuset);
CPU_SET(0, &cpuset);  // Allow core 0
CPU_SET(1, &cpuset);  // Allow core 1
sched_setaffinity(0, sizeof(cpuset), &cpuset);
```

**Result:** Thread can run on core 0 or 1, but never 2 or 3.

---

## Exercise 3: Optimal Core Selection

### Which Core to Choose?

**Check your system:**
```bash
# How many cores?
nproc
# Output: 4

# Core topology
lscpu | grep -E "^CPU\(s\)|Core\(s\) per socket|Socket\(s\)"
# Example output:
# CPU(s):                4
# Core(s) per socket:    2
# Socket(s):             2
```

**Strategy:**
1. **Choose core 0 for simplicity** (guaranteed to exist)
2. **Avoid core 0 if it's busy** (check `top`)
3. **Use isolated core if available** (advanced, needs kernel boot param)

---

### Isolate Core at Boot (Advanced)

**Edit `/etc/default/grub`:**
```bash
# Isolate core 3 for audio
GRUB_CMDLINE_LINUX="isolcpus=3"
```

**Update grub and reboot:**
```bash
sudo update-grub
sudo reboot
```

**Now core 3 is dedicated to your process:**
```bash
taskset -c 3 chrt -f 10 ./game
# Core 3 has ZERO interference from other processes!
```

---

## Concept 3: Cache Line Bouncing (Multi-Threaded Audio)

### The Problem: False Sharing

**If your game has separate render and audio threads:**
```c
struct GameState {
  // Render thread writes these
  int frame_count;
  float camera_x;
  float camera_y;
  
  // Audio thread writes these  â† Same cache line!
  int audio_sample_index;
  float audio_volume;
};
```

**If both variables in same 64-byte cache line:**
```
Core 0 (Render):  Writes frame_count â†’ Cache line invalidated on Core 1
Core 1 (Audio):   Reads audio_sample_index â†’ Reload cache line (slow!)
```

**Result:** Ping-pong effect = cache line bounces between cores.

---

### Solution: Padding

```c
struct GameState {
  // Render thread
  int frame_count;
  float camera_x;
  float camera_y;
  
  char padding[64];  // â† Force audio data to separate cache line
  
  // Audio thread
  int audio_sample_index;
  float audio_volume;
};
```

**Now:** Separate cache lines = no bouncing!

---

## Exercise 4: Combined Real-Time + Affinity

**Ultimate audio setup:**
```c
#include <sched.h>
#include <pthread.h>

int LinuxOptimizeAudioThread(int core_id, int rt_priority) {
  // Step 1: Pin to CPU core
  cpu_set_t cpuset;
  CPU_ZERO(&cpuset);
  CPU_SET(core_id, &cpuset);
  
  if (sched_setaffinity(0, sizeof(cpuset), &cpuset) == -1) {
    perror("sched_setaffinity");
    return -1;
  }
  
  // Step 2: Set real-time priority
  struct sched_param param = { .sched_priority = rt_priority };
  
  if (sched_setscheduler(0, SCHED_FIFO, &param) == -1) {
    perror("sched_setscheduler");
    return -1;
  }
  
  printf("âœ… Audio thread optimized: Core %d, RT priority %d\n", 
         core_id, rt_priority);
  
  return 0;
}

int main() {
  // Optimize for core 0, priority 10
  LinuxOptimizeAudioThread(0, 10);
  
  LinuxMainLoop();
}
```

**Test:**
```bash
./game

# In another terminal:
ps -eo pid,psr,class,rtprio,comm | grep game
# PID  PSR CLS RTPRIO CMD
# 1234  0   FF    10   game

# PSR = Processor (core 0)
# CLS = FF (SCHED_FIFO)
# RTPRIO = 10
```

**Perfect!** ğŸ¯

---

## Concept 4: Hyper-Threading Considerations

### Physical vs Logical Cores

**Your CPU might have:**
```
Physical cores: 2
Logical cores:  4 (2 per physical via hyper-threading)

Mapping:
  Core 0, 1 â†’ Physical core 0
  Core 2, 3 â†’ Physical core 1
```

**Problem:** Cores 0 and 1 share execution units!

**Check topology:**
```bash
lscpu -e
# CPU NODE SOCKET CORE L1d:L1i:L2:L3 ONLINE
#   0    0      0    0 0:0:0:0       yes
#   1    0      0    0 0:0:0:0       yes    â† Same physical core as 0!
#   2    0      0    1 1:1:1:0       yes
#   3    0      0    1 1:1:1:0       yes    â† Same physical core as 2!
```

**Best practice:** Pin to physical cores (0, 2), not logical (0, 1).

---

## Self-Check Quiz

### Question 1
**Why does thread migration hurt performance?**

A) More CPU instructions  
B) Cache invalidation  
C) Network latency  
D) Disk I/O  

<details>
<summary>Answer</summary>

**B) Cache invalidation**

When a thread moves to a different core, its data is not in the new core's L1/L2 cache. Must reload from slower RAM or L3.
</details>

---

### Question 2
**What does `taskset -c 0 ./game` do?**

A) Runs game on all cores  
B) Pins game to core 0  
C) Sets priority to 0  
D) Disables core 0  

<details>
<summary>Answer</summary>

**B) Pins game to core 0**

`taskset -c` sets CPU affinity. Game thread can only run on specified core(s).
</details>

---

### Question 3
**How big is a cache line on x86-64?**

A) 8 bytes  
B) 32 bytes  
C) 64 bytes  
D) 128 bytes  

<details>
<summary>Answer</summary>

**C) 64 bytes**

x86-64 CPUs use 64-byte cache lines. This is why false sharing happens when variables are close together in memory.
</details>

---

### Question 4
**What's the benefit of isolated CPUs (`isolcpus=3`)?**

A) Higher clock speed  
B) No scheduler interruptions  
C) More cache  
D) Better cooling  

<details>
<summary>Answer</summary>

**B) No scheduler interruptions**

Isolated cores are not used by Linux scheduler for normal processes. Only processes explicitly pinned to them run there = zero interference.
</details>

---

### Question 5
**Should you pin audio thread if you only have 2 cores?**

A) Yes, always  
B) No, let scheduler decide  
C) Only if using real-time priority  
D) Depends on workload  

<details>
<summary>Answer</summary>

**D) Depends on workload**

On 2-core systems, pinning might prevent load balancing benefits. Test both ways. On 4+ cores, pinning is more beneficial.
</details>

---

## Key Takeaways

### Cache Hierarchy Summary

| Cache | Size | Speed | Shared? |
|-------|------|-------|---------|
| **L1** | 32 KB | 1 cycle | Per-core |
| **L2** | 256 KB | 10 cycles | Per-core |
| **L3** | 8 MB | 40 cycles | All cores |
| **RAM** | 16 GB | 200 cycles | All cores |

**Goal:** Keep audio data in L1/L2 by avoiding thread migration.

---

### Affinity Commands

```bash
# Pin to core 0
taskset -c 0 ./game

# Pin to cores 0 and 2
taskset -c 0,2 ./game

# Check affinity of running process
taskset -p $(pgrep game)

# Isolate core (in /etc/default/grub)
isolcpus=3
```

---

### Code Template

```c
#include <sched.h>

int PinToCore(int core_id) {
  cpu_set_t cpuset;
  CPU_ZERO(&cpuset);
  CPU_SET(core_id, &cpuset);
  return sched_setaffinity(0, sizeof(cpuset), &cpuset);
}

int main() {
  PinToCore(0);  // Pin to core 0
  // ... rest of program
}
```

---

## Connection to Other Lessons

**Prerequisites:**
- L7.1: Scheduling Classes (RT priority)
- L5.5: Memory Management (cache-friendly layouts)

**Enables:**
- L7.3: Priority Inversion (RT + affinity pitfalls)
- L8.1: Performance Profiling (stable CPU = easier profiling)
- L8.3: Lock-Free Buffers (cache line considerations)

---

## Next Lesson Preview

**L7.3: Priority Inversion & Mutexes**
- What if RT thread waits on mutex?
- Mars Pathfinder bug (classic case study)
- Priority inheritance protocol
- How to debug inversion

---

**Estimated Completion Time:** 60-75 minutes  
**Difficulty:** â­â­â­â­â˜† (Advanced)  
**Competence Level Achieved:** 5/6 (Synthesis)

**Progress:** Unit 7 is 67% complete! (2/3 lessons done)

